import os, sys
import gym
import gym.spaces
from gym.utils import seeding
import numpy as np
import configparser
from cffi import FFI
sys.path.append('../')
from edges import Edge

class SimEnv(gym.Env):
    metadata = {'render.modes': ['human']}
    def __init__(self):
        super().__init__()
        config = configparser.ConfigParser()
        config.read('config.ini')
        self.num_agents = config.getint('SIMULATION', 'num_agents')
        self.num_edges  = config.getint('SIMULATION', 'num_edges')
        self.obs_step   = config.getint('TRAINING',   'obs_step')
        datadir         = config.get('SIMULATION',    'datadir')

        self.init = True

        self.dist  = np.zeros(self.num_edges * self.obs_step)
        self.width = np.zeros(self.num_edges * self.obs_step)
        self.edges = Edge()
        for e, idx in self.edges.observed_edge.items():
            fr, to = e
            for n in range(self.obs_step):
                self.dist[idx + n * self.num_edges]  = self.edges.dist[fr, to]
                self.width[idx + n * self.num_edges] = self.edges.width[fr, to]

        agentfn    = os.path.dirname(os.path.abspath(__file__)) + "/../%s/agentlist.txt"%datadir
        self.speed = self.get_speed(agentfn)

        self.action_space      = gym.spaces.Discrete(7)
        self.observation_space = gym.spaces.Box(
                low=0,
                high=self.num_agents,
                shape=np.zeros(self.num_edges * self.obs_step).shape
                )
        self.state = None
        assert self.action_space.n == 7
        assert self.observation_space.shape[0] == self.num_edges * self.obs_step

    def step(self, action):
        _action = self._get_action(action)
        self.call_traffic_regulation(_action, self.num_step)
        self.state = self._get_observation(self.cur_time + self.interval)
        travel_time = self._get_travel_time(self.state)
        reward = self._get_reward(self.state)
        self.episode_reward += travel_time
        print("CURRENT", self.cur_time, action, reward, self.episode_reward)
        self.num_step += 1
        self.cur_time += self.interval
        done = self.max_step == self.num_step
        info = {}
        if done:
            info = {
                    "episode": {
                        "r": self.episode_reward
                        }
                    }
        return self.state, reward, done, info # obseration, reward, done, info

    def reset(self):
        config = configparser.ConfigParser()
        config.read('config.ini')

        self.sim_time  = config.getint('SIMULATION', 'sim_time')
        self.interval  = config.getint('SIMULATION', 'interval')
        self.max_step  = int( np.ceil( self.sim_time / self.interval ))
        self.cur_time  = 0
        self.num_step  = 0
        self.state     = np.zeros(self.num_edges * self.obs_step)

        self.episode_reward = 0

        self.reset_sim() # set up simulation

        actions = [[0, 0, 0, 0, 0, 0],
                [0, 0, 0, 0, 0, 1],
                [0, 0, 0, 0, 1, 0],
                [0, 0, 0, 1, 0, 0],
                [0, 0, 1, 0, 0, 0],
                [0, 1, 0, 0, 0, 0],
                [1, 0, 0, 0, 0, 0]]
        self.actions = np.array(actions)
        return self.state

    def render(self, mode='human', close=False):
        pass

    def close(self):
        pass

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def _get_action(self, action):
        return self.actions[action]

    def _get_reward(self, observation):
        # moving speedをRewardとする
        # 最大値を取るか，平均を取るかは要検討
        # 全歩行者数でRewardを決定
        # v_max = self.speed
        # th    = 1.8 / (v_max + 0.3)
        # observation = observation / (self.dist * self.width)
        # observation = np.where(observation == 0, float('-inf'), observation)            # if rho == 0 then reward is 1
        # observation = np.where(observation >= 6, -observation, observation) # if rho >= 6 then reward is 0
        # observation = np.where((th <= observation) & (observation <= 6), 1.8 * observation ** (-1) - 0.3, 1)
        # return observation.mean()

        # 混雑の最大値を抑えたい
        # v_max = self.speed
        # th    = 1.8 / (v_max + 0.3)
        # rho   = np.max(observation)
        # if rho >= 6:
        #     return -np.max(observation)
        # elif th <= rho and rho < 6:
        #     return 1.8 * np.max(observation) ** (-1) - 0.3
        # return 1.0

        # 旅行時間の平均
        return self._get_travel_time(observation)
        # 過去Nステップの旅行時間の平均
        # return -np.sum(observation) * self.interval / self.num_agents / self.obs_step

    def _get_travel_time(self, observation):
        observation = observation[self.num_edges * (self.obs_step-1):]
        return np.sum(observation) * self.interval / self.num_agents

    def call_traffic_regulation(self, action, t):
        """
        Take action, i.e., open/close gates
        """
        events = self.get_events(action, t)
        for e in events:
            self.lib.setBombDirect(e.encode('ascii'))
            # print(e)
    
    def call_edge_cnt(self, stop_time=0):
        """
        Count the number of agents on the edge
        """
        self.lib.setStop(stop_time)
        self.lib.iterate()
        # ret = np.zeros(len(self.edges.dict_edge))
        # for e, idx in self.edges.dict_edge.items():
        ret   = np.zeros(len(self.edges.observed_edge))
        dist  = np.zeros(len(self.edges.observed_edge))
        width = np.zeros(len(self.edges.observed_edge))
        for e, idx in self.edges.observed_edge.items():
            fr, to     = e
            ret[idx]   = self.lib.cntOnEdge(fr-1, to-1)
        return ret

    def _get_observation(self, stop_time=0):
        obs     = self.state[self.num_edges:]
        cur_obs = self.call_edge_cnt(stop_time)
        return np.append(obs, cur_obs)

    def get_events(self, action, t):
        """
        e.g., return 1000 traffic_regulation 343 767 1
        e.g., return 1000 traffic_regulation 343 767 0
        """
        time = t * self.interval + 1
        goal_edge = [(767,343), (768,347), (769,766), (770,765), (771,319), (772,150)]
        events = []
        for i in range(len(action)):
            fr, to = goal_edge[i]
            out = "%d traffic_regulation %d %d"%(time, to, fr)
            if action[i] == 1:
                out += " 1"
            else:
                out += " 0"
            # print("TRAFFIC_REGULATION", action, out)
            events.append(out)
        return events
    def reset_sim(self):
        print("reset simulator configure")
        if self.init:
            config = configparser.ConfigParser()
            config.read('config.ini')
            datadir  = config.get('SIMULATION', 'datadir')
            libsimfn = os.path.dirname(os.path.abspath(__file__)) + "/../bin/libsim.so"
            agentfn  = os.path.dirname(os.path.abspath(__file__)) + "/../%s/agentlist.txt"%datadir
            graphfn  = os.path.dirname(os.path.abspath(__file__)) + "/../%s/graph.twd"%datadir
            goalfn   = os.path.dirname(os.path.abspath(__file__)) + "/../%s/goallist.txt"%datadir
            sim_time = config.get('SIMULATION', 'sim_time')
            self.ffi = FFI()
            self.lib = self.ffi.dlopen(libsimfn)
            self.ffi.cdef("""
            void init(int argc, char** argv);
            int setStop(int t);
            void iterate();
            void setBombDirect( char *text);
            int cntOnEdge(int fr, int to);
            void restart();
            """) 
            argv = [sys.argv[0]]
            argv.extend([
                agentfn,
                graphfn,
                goalfn,
                "-o",
                "result",
                "-l",
                "9999999",
                "-e",
                sim_time
                ])
            tmp = []
            for a in argv:
                tmp.append(self.ffi.new("char []", a.encode('ascii')))
            argv = self.ffi.new("char *[]", tmp)
            # call simulator
            self.lib.init(len(argv), argv)
            # save initial state
            self.init = False
        else:
            # load inital state
            self.lib.restart()

    def get_speed(self, agentfn):
        with open(agentfn) as f:
            lines = f.readlines()
            return sum([float(l.split('\t')[2]) for l in lines[1:]]) / float(lines[0].split(' ')[0])

